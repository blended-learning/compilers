{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "104e285f8889417e86d3e43f648a5854"
   },
   "source": [
    "# Lab 2\n",
    "\n",
    "## Lexical Analyzer for JSON\n",
    "\n",
    "In this lab, we will be building a lexical analyzer for simple JSON files.  We will be using ANTLR.\n",
    "\n",
    "The learning objectives:\n",
    "\n",
    "1. Understand the workflow of using ANTLR tools.\n",
    "2. Be able to build lexical analyzers using ANTLR.\n",
    "\n",
    "<p style=\"border: 2px solid red; text-align: center; padding: 20px; font-size: 150%;\"> For this lab, you will need to use Terminal for part of your work. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "5a2f16f7080a4a148ab47af7a762beb4",
    "lambdacheck": {
     "layout": {
      "column_span": 5,
      "row_span": 10
     }
    }
   },
   "source": [
    "You will need to restart the kernel whenever you update the ANTLR generated Java classes.\n",
    "\n",
    "We have provided a Makefile to help you to recompile your ANTLR code.\n",
    "\n",
    "```\n",
    "$ make build\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "c50fe015adc74d9e9c8861b88dc4d6a0",
    "lambdacheck": {
     "layout": {
      "column_offset": 5
     }
    }
   },
   "outputs": [],
   "source": [
    "@file:DependsOn(\"/data/shared/antlr-4.9.1-complete.jar\")\n",
    "@file:DependsOn(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f5857b10fcac47cbac4cbef17af13c33",
    "lambdacheck": {
     "layout": {
      "column_span": 5,
      "row_span": 10
     }
    }
   },
   "source": [
    "Let's create a simple JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "b5b0615661674f2c89e7948df3b20ea1",
    "lambdacheck": {
     "layout": {
      "column_offset": 5
     }
    }
   },
   "outputs": [],
   "source": [
    "import java.io.File;\n",
    "\n",
    "val jsonSample = \"\"\"\n",
    "    {\n",
    "        \"name\": \"CSCI 4020U\",\n",
    "        \"title\": \"Compilers\",\n",
    "        \"enrollment\": 89,\n",
    "        \"lectures\": [\n",
    "            {\n",
    "                \"day\": \"Monday\",\n",
    "                \"time\": \"11-12:30\"\n",
    "            },\n",
    "            {\n",
    "                \"day\": \"Thursday\",\n",
    "                \"time\": \"11-12:30\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\"\"\".trimIndent()\n",
    "\n",
    "File(\"./sample.json\").writeText(jsonSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0e354dfb5794438d88cdae6e256f607d",
    "lambdacheck": {
     "layout": {
      "column_span": 5,
      "row_span": 10
     }
    }
   },
   "source": [
    "We load the generated lexer and its dependencies from ANTLR runtime library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "f9e6739b2bcd427781932aa978b37926",
    "lambdacheck": {
     "layout": {
      "column_offset": 5
     }
    }
   },
   "outputs": [],
   "source": [
    "import org.antlr.v4.runtime.*\n",
    "import lab2.JsonLexer;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d0a5be9154974167887f1c7813e3b6fe",
    "lambdacheck": {
     "layout": {
      "column_span": 5,
      "row_span": 10
     }
    }
   },
   "source": [
    "Construct an ANTLR character stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "6347a2dd54d546808082d9e06cfe8ec8",
    "lambdacheck": {
     "layout": {
      "column_offset": 5
     }
    }
   },
   "outputs": [],
   "source": [
    "val input = ANTLRFileStream(\"./sample.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b92930856d17438196cc2e811e653dd8",
    "lambdacheck": {
     "layout": {
      "column_span": 5,
      "row_span": 10
     }
    }
   },
   "source": [
    "Construct a lexer that processes the character stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "ba26bdfbb97d42aa8a2ad0e51ccb8f52",
    "lambdacheck": {
     "layout": {
      "column_offset": 5
     }
    }
   },
   "outputs": [],
   "source": [
    "val lexer = JsonLexer(input);\n",
    "lexer.removeErrorListeners()\n",
    "lexer.addErrorListener(object: BaseErrorListener() {\n",
    "  override fun syntaxError(recognizer: Recognizer<*,*>,\n",
    "               offendingSymbol: Any?,\n",
    "               line: Int,\n",
    "               pos: Int,\n",
    "               msg: String,\n",
    "               e: RecognitionException) {\n",
    "      throw Exception(\"${e} at line:${line}, char:${pos}\")\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fe137bef0f5348e2b435d7d316557213",
    "lambdacheck": {
     "layout": {
      "column_span": 5,
      "row_span": 10
     }
    }
   },
   "source": [
    "Obtain the token stream, and trigger the scan of the input character stream by the lexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "6074f0a61444485e8ffa5d51e2ac5368",
    "lambdacheck": {
     "layout": {
      "column_offset": 5
     }
    }
   },
   "outputs": [],
   "source": [
    "val tokens = CommonTokenStream(lexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "3385fb0d5cb2444cb653a99f571692b7",
    "lambdacheck": {
     "check": {
      "_immediate": true,
      "_name": "",
      "display.text/plain": true,
      "output.stderr": true,
      "output.stdout": true,
      "result.text/plain": true
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"{\" is a '{'\n",
      "\"\"name\"\" is a String\n",
      "\":\" is a ':'\n",
      "\"\"CSCI 4020U\"\" is a String\n",
      "\",\" is a ','\n",
      "\"\"title\"\" is a String\n",
      "\":\" is a ':'\n",
      "\"\"Compilers\"\" is a String\n",
      "\",\" is a ','\n",
      "\"\"enrollment\"\" is a String\n",
      "\":\" is a ':'\n",
      "\"89\" is a Number\n",
      "\",\" is a ','\n",
      "\"\"lectures\"\" is a String\n",
      "\":\" is a ':'\n",
      "\"[\" is a '['\n",
      "\"{\" is a '{'\n",
      "\"\"day\"\" is a String\n",
      "\":\" is a ':'\n",
      "\"\"Monday\"\" is a String\n",
      "\",\" is a ','\n",
      "\"\"time\"\" is a String\n",
      "\":\" is a ':'\n",
      "\"\"11-12:30\"\" is a String\n",
      "\"}\" is a '}'\n",
      "\",\" is a ','\n",
      "\"{\" is a '{'\n",
      "\"\"day\"\" is a String\n",
      "\":\" is a ':'\n",
      "\"\"Thursday\"\" is a String\n",
      "\",\" is a ','\n",
      "\"\"time\"\" is a String\n",
      "\":\" is a ':'\n",
      "\"\"11-12:30\"\" is a String\n",
      "\"}\" is a '}'\n",
      "\"]\" is a ']'\n",
      "\"}\" is a '}'\n",
      "\"<EOF>\" is a EOF\n"
     ]
    }
   ],
   "source": [
    "// Now we can display all the tokens extracted\n",
    "// by the lexer.\n",
    "\n",
    "try {\n",
    "    tokens.fill()\n",
    "    val tokenTypeNames = lexer.tokenNames;\n",
    "    tokens.getTokens().forEach {\n",
    "        token: Token ->\n",
    "        val typeName: String = if(token.type < 0) {\n",
    "            \"EOF\"\n",
    "        } else {\n",
    "            tokenTypeNames[token.type]\n",
    "        }\n",
    "        println(\"\\\"${token.text}\\\" is a ${typeName}\")\n",
    "    }\n",
    "} catch(e:Exception) {\n",
    "    println(e)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4ac5ec45955c4f9588e94cf764b7d701"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Î».check",
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "codemirror_mode": "text/x-kotlin",
   "file_extension": ".kt",
   "mimetype": "text/x-kotlin",
   "name": "kotlin",
   "pygments_lexer": "kotlin",
   "version": "1.4.30-dev-3354"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
